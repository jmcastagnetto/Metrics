% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/binary_classification.R
\name{sensitivity}
\alias{sensitivity}
\title{Sensitivity}
\usage{
sensitivity(actual, predicted)
}
\arguments{
\item{actual}{The ground truth binary numeric vector containing 1 for the positive
class and 0 for the negative class.}

\item{predicted}{The predicted binary numeric vector containing 1 for the positive
class and 0 for the negative class. Each element represents the
prediction for the corresponding element in \code{actual}.}
}
\description{
\code{sensitivity} calculates the proportion of actual positives (\code{actual} equals 1)
that are correctly identified as such. It is also known as
\code{true positive rate} or \code{recall}.
}
\examples{
actual <- c(1, 1, 1, 0, 0, 0)
predicted <- c(1, 0, 1, 1, 1, 1)
sensitivity(actual, predicted)
}
\seealso{
\code{\link{confusion_matrix}} \code{\link{specificity}}
}
